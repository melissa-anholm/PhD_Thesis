% !TEX root = ../thesis_main.tex



%%%% --- * --- %%%%
\clearpage	
%\chapter{Estimating Systematic Effects}
\chapter{Analysis and Estimates of Systematic Effects}
\label{systematics_chapter}
\label{analysis_chapter} 
\note[done,nolist]{John proposes the following intro statement for this Ch.~\ref{analysis_chapter} The following two(one) paragraphs are (almost) a direct quote from him:  }

The collaboration has performed an independent analysis using (mostly) the same set of data to measure $\Abeta$, fixing $\bFierz$ to zero.
Differences with that analysis are interleaved in this section~\aside{Are they even though??} and summarized in Appendix~\ref{ch:differences_data}.
Critical physics improvements concern an eMCP-beta timing walk correction which enabled an improved cut against background, also incorporating a more complete modelling of decay backgrounds from untrapped atoms. Technical corrections include a correct treatment of the polarization cycle.
An arbitrary change in the DSSD
%deltaE 
radius cut is kept self-consistent.
%}




%%%% --- * --- %%%%
%%%% --- * --- %%%%
\FloatBarrier
\section{Comparing Simulations to Experimental Data:  The General Methodology}
\label{sec:comparing_data_sims}
The primary parameter measurement strategy in this project involved comparing the experimental data to a 2D parameter space of simulations, and this is true both for evaluation of the best parameter values, and also for evaluations of the uncertainties.  

As described in Section~\ref{signature_chapter}, and in more detail in Appendix~\ref{appendix:superratio}, the primary experimental observable is the superratio asymmetry, which is constructed from four experimental \emph{rates} of beta detection:
\bea
A_{\mathrm{super}}(\Ebeta) 
&=& 
\frac{ \sqrt{r_{\mathrm T-}\, r_{\mathrm B+} \phantom{ (\!\!\!\!\!) } }\; -\, \sqrt{ r_{\mathrm T+}\, r_{\mathrm B-}\phantom{ (\!\!\!\!\!) }} }{ \sqrt{r_{\mathrm T-}\, r_{\mathrm B+}\phantom{ (\!\!\!\!\!) }} \;+\, \sqrt{r_{\mathrm T+}\, r_{\mathrm B-} \phantom{ (\!\!\!\!\!) }} }.
\eea
This quantity is closely related to the two fundamental parameters we hope to extract, 
%$\Abeta$ and $\bFierz$, 
and in the absence of certain systematic effects, we can cleanly describe a relationship between the observable
%, $A_{\mathrm{super}}(\Ebeta)$, 
and the two physical parameters ($\Abeta$ and $\bFierz$) that we might use to describe the shape of an experimentally measured $A_{\mathrm{super}}(\Ebeta)$ curve:
\bea
A_{\mathrm{super}}(\Ebeta) 
&=&
%&\approx& 
\frac{\Abeta \, \frac{v}{c} \, |\vec{P}| \, \langle | \cos\theta | \rangle
}{
1 + \bFierz \frac{mc^2}{\Ebeta}
}.
\label{eq:AsuperAbetabFierz}
\eea

Of course, when all systematics are properly accounted for, Eq.~(\ref{eq:AsuperAbetabFierz}) is no longer an adequate description of the full relationship between the observable and physical parameters and a comparison to Monte Carlo must be used.  A series of Geant4 simulations are performed and the results are (re-)processed with slightly different cuts and calibrations so as to match with the experimental conditions in each of the three electron datasets, and the superratio asymmetries are constructed.  The degree to which the simulations and experiment match is evaluated by using a $\chi^2$ comparison of the superratio asymmetries as the figure of merit (see Figs.~\ref{fig:asymmetryB},~\ref{fig:asymmetryC},~\ref{fig:asymmetryD}).  This is repeated for a range of $\Abeta$ and $\bFierz$ values, and a $\chi^2$ mapping of the 2D parameter space is produced.  

%
\begin{figure}[h!t!b!]
	\centering
	\includegraphics[width=.999\linewidth]
	{Figures/BestAsymmetry_SetB.png}
	\caption[SetB Superratio Asymmetry]{A superratio asymmetry from Dataset B (red) with 1$\sigma$ statistical errors, and the best fit results (evaluated from 400 keV--4800 keV) from simulations.  %\copyright~2022 Melissa Anholm.
	}	
	\label{fig:asymmetryB}
\end{figure}
%
\begin{figure}[h!t!b!]
	\centering
	\includegraphics[width=.999\linewidth]
	{Figures/BestAsymmetry_SetC.png}
	\caption[SetC Superratio Asymmetry]{A superratio asymmetry from Dataset C (red) with 1$\sigma$ statistical errors, and the best fit results (evaluated from 400 keV--4800 keV) from simulations.  %\copyright~2022 Melissa Anholm.
	}	
	\label{fig:asymmetryC}
\end{figure}
%	
\begin{figure}[h!t!b!]
	\centering
	\includegraphics[width=.999\linewidth]
	{Figures/BestAsymmetry_SetD.png}
	\caption[SetD Superratio Asymmetry]{A superratio asymmetry from Dataset D (red) with 1$\sigma$ statistical errors, and the best fit results (evaluated from 400 keV--4800 keV) from simulations.  %\copyright~2022 Melissa Anholm.
	}	
	\label{fig:asymmetryD}
\end{figure}
%

For each superratio asymmetry constructed from simulated spectra, the scintillator spectra from which the superratio asymmetry is comprised are created as a linear combination of Geant4 beta decay events originating from the atom cloud and from surfaces within the chamber.  Both components of the spectra are combined event-by-event with SOE events generated in COMSOL, as described in Sections~\ref{sec:bs} and~\ref{sec:tof_bg}, as this is necessary for the critical time-of-flight cut on the ``SOE -- Beta'' spectra.  For decays originating within the atom cloud, both the primary decay branch and the subdominant `two percent' branch are allowed to contribute events, and only the dominant branch is varied as a function of BSM couplings.  For background events, only the Standard Model primary branch is simulated.  

A major caveat to the above description is that running a high statistics G4 simulation of our experiment is a computationally expensive process, so it was not possible to perform a separate simulation at every `pixel' within the parameter space.  Instead, to evaluate how well the experimental data matched to the expectation for varying values of $\Abeta$ and $\bFierz$, only three simulations were performed for different values of $\bFierz$, all using the same nominal value for $\Abeta$.  The $A_{\mathrm{super}}(\Ebeta)$ spectra representing intermediate $\bFierz$ values were created from a linear combination of spectra generated at the two closest values of $\bFierz$.

To vary the effective $\Abeta$ value, the generated $A_{\mathrm{super}}(\Ebeta)$ spectrum was simply scaled.  From Eq.~(\ref{eq:AsuperAbetabFierz}) it is clear that this works well so long as $\bFierz$ is small and any systematics are evaluated separately.  This method allows for an arbitrarily finely pixellated 2D $\chi^2$ map to be created.  It is done separately for each of the three experimental data sets so as to facilitate evaluation of systematic effects that changed between runsets.  See Figs.~\ref{fig:2dchi2_setB},~\ref{fig:2dchi2_setC}, and~\ref{fig:2dchi2_setD}.

\begin{figure}[h!tb]
	\centering
	\includegraphics[width=.999\linewidth]
	{Figures/Chi2_2D_SetB.png}
	\note{Systematic uncertainties are evaluated by adjusting parameters and creating a new (set of) chi2 maps very much like this one.}
%	\note[tag]{On the per-dataset $\chi^2$ maps and SR asymmetries, go through and write descriptions for the goddamn pictures.}
	\caption[$\chi^2$ Map for Runset B]{A $\chi^2$ map to compare data from Runset B to a parameter space of $\Abeta$ and $\bFierz$ values.  The contours show 1$\sigma$, 90\%, and 95\% statistical confidence intervals, and the minimum reduced $\chi^2$ value is 0.9216.  
	%\copyright~2022 Melissa Anholm.
	}	
	\label{fig:2dchi2_setB}
\end{figure}
%
\begin{figure}[h!tb]
	\centering
	\includegraphics[width=.999\linewidth]
	{Figures/Chi2_2D_SetC.png}
	\caption[$\chi^2$ Map for Runset C]{A $\chi^2$ map to compare data from Runset C to a parameter space of $\Abeta$ and $\bFierz$ values.  The contours show 1$\sigma$, 90\%, and 95\% statistical confidence intervals, and the minimum reduced $\chi^2$ value is 1.0064.  
%	\copyright~2022 Melissa Anholm.
	}	
	\label{fig:2dchi2_setC}
\end{figure}
%
\begin{figure}[h!tb]
	\centering
	\includegraphics[width=.999\linewidth]
	{Figures/Chi2_2D_SetD.png}
	\caption[$\chi^2$ Map for Runset D]{A $\chi^2$ map to compare data from Runset D to a parameter space of $\Abeta$ and $\bFierz$ values.  The contours show 1$\sigma$, 90\%, and 95\% statistical confidence intervals, and the minimum reduced $\chi^2$ value is 0.9567.  
	%\copyright~2022 Melissa Anholm.
	}	
	\label{fig:2dchi2_setD}
\end{figure}



\note{We can do this whole chi2 map thing again for real- and simulated data sets with different values of parameters that we vary as *systematics.*  Note how the best values of $\Abeta$ and $\bFierz$ change when each of the systematics are varied.}

%%%%That old list:
%%%%\begin{itemize}
%%%%	\item For each of those 3 simulations, sort the ``good'' data according to emission angle relative to the detector.  Do each detector individually.  For both polarizations.
%%%%	\item We can do this whole thing again for simulated data sets with different values of parameters that we vary as systematics.  Note how the best values of $\Abeta$ and $\bFierz$ change when each of the systematics are varied.
%%%%\end{itemize}
%%%%


\FloatBarrier
\section{Evaluation of Systematic Effects}
\label{section:systematics}
\subsection{Beta Scattering}
%\section{Quantifying the Effects of Backscatter with Geant4}
\label{section:scattering_systematics}
%\note[org]{This content got moved over *there*.  (ie, Section~\ref{sec:bs}.)}
The methodology used to simulate and model scattered events is described in Section~\ref{sec:bs}.  To evaluate the systematic effect on the final measurements arising from incomplete knowledge of how much beta scattering is present (i.e., how well we can trust the simulation to correctly model the amount of scattering), 
%To evaluate the systematic effects arising from incomplete knowledge of how much beta scattering is present, 
two sets of $\chi^2$ maps very much like those in Section~\ref{sec:comparing_data_sims} are created, with the amount of scattering varied by one standard deviation.  This does not require a new simulation;  instead, for the three high statistics G4 simulations varying the BSM scalar coupling, all events passing the cuts are categorized into unscattered and forward-scattered events, sidescattered events, and backscattered events, depending on a comparison of the beta's emission angle to the detector in which it was eventually observed, as shown in Fig.~\ref{fig:soe_tof_vs_costheta}.

The contribution from unscattered and forward scattered events is not allowed to vary, but the weights attributed to sidescattered and backscattered events was varied by $\pm 10\%$ and $\pm 5.1\%$ (respectively) relative to their `best' values.  Fig.~\ref{fig:asymmetry_scattering} clearly shows the change in superratio asymmetry produced by this variation in the amount of scattering.  The method by which it was determined how much the scattering weights should be allowed to vary is benchmarked in Refs.~\cite{stragglingLonergan1970} \cite{stragglingRester1971}, and is described further in the supplementary material of a recent publication by the collaboration~\cite{ben_Abeta}.

\begin{figure}[h!tb]
	\centering
	\includegraphics[width=.999\linewidth]{Figures/ScatteringEstimate.png}
	\caption[Scattering Effects in the Asymmetry]{The amount of scattering is adjusted by one standard deviation in both directions, and the results to the superratio asymmetry are plotted.  Backscattering and sidescattering errors are conservatively treated as being fully correlated.  The bulk of the effect occurs at lower energies, where sensitivity to $\bFierz$ is at its highest.  }	
	\label{fig:asymmetry_scattering}
\end{figure}

Since errors in evaluating both side-scatter and backscatter arise from limitations on how well Geant4 is expected to perform, it is not clear how correlated these errors are, but it seems foolish to suppose they should not be correlated at all.  Therefore, the conservative assumption that the two are \emph{fully} correlated is taken, and the errors from side-scatter and backscatter are added \emph{linearly} to one another before being combined in quadrature with the other uncertainties.  

As this is the dominant systematic error, the TRINAT collaboration is working to improve the experimental design to use lower-Z materials to reduce the size of this effect.




\subsection{Detector Calibrations and Thresholds}
\subsubsection{Scintillators}
\note{I could and probably *should* add a description of the scintillator threshold uncertainty evaluation.  But I'm going to skip that for Round 1 and see if anybody notices.}
The two plastic scintillators were calibrated by the collaboration using online data, with reference points from the beta spectrum endpoint and the compton edge arising from annihilation radiation.  Calibration was performed using only \emph{polarized} data, because the final measurements use only polarized data, and the scintillator gain is more stable in the absence of the stronger oscillating magnetic fields from the AC-MOT.  

A linear calibration is used to extract $E_{\textrm{scint}}$, the energy absorbed in the scintillator, from $Q_{\textrm{QDC}}$, the raw signal reported by the \ac{QDC}, with
\bea
E_{\textrm{scint}} &=& \frac{1}{m}(Q_{\textrm{QDC}} - b), 
\eea
and the detector resolution arising from photon counting statistics is given by
\bea
\sigma(E_{\textrm{scint}}) &=& \sqrt{\lambda E_{\textrm{scint}}}.
\eea
In the above, $m$ and $b$ are simply the parameters for a linear calibration, and $\lambda$ is a parameter that characterizes the detector's resolution independent of photon counting statistics.

During online data collection, one \ac{QDC} module failed abruptly and had to be replaced.  As a result, the collected data is calibrated separately before and after the module failure, and the calibrations change slightly at this time. The methodology used is described in detail within~\cite{ben_thesis}, so the results will simply be stated here in Table~\ref{table:scintcal}.
\input{table_scintcal}

To evaluate the systematic effects associated with the scintillators' calibrations, the calibration for each scintillator is adjusted independently to produce energy measurements that are higher by one standard deviation, and lower by one standard deviation, and the resulting changes to the $\chi^2$ map's $\Abeta$ and $\bFierz$ centroids is measured.  For this, the datasets corresponding to both sets of calibration numbers have their calibrations adjusted simultaneously, but each individual scintillator is treated separately.  There is no reason to think the two scintillators' calibration accuracies should be correlated, so errors resulting from a changed scintillator calibration are added to one another in quadrature.

%%%%Uncertainties resulting from an inaccurate scintillator calibration are added in quadrature for the final result, because there is no reason to think the two scintillators' calibration inaccuracies should be correlated.
%%%%
%%%%Because it is not immediately intuitively obvious how different a calibration mistake on both scintillators might change the resulting measurement of $\bFierz$, 
%%%%There is no reason to believe the errors in calibration should be correlated, so 

\subsubsection{DSSD Radius, Energy Threshold, Agreement}
%\section{BB1 Radius, Energy Threshold, Agreement}
\label{section:bb1_systematics}
%\note[tag]{Write section dssd systematics evaluation.}
Several parameters relating to our choice of cuts relating to DSSD calibrations are varied within both the experimental data and the simulated data to which it is compared.  The detection radius, the overall energy threshold, the strip-by-strip SNR, and the energy and timing agreement (See Ch.~\ref{sec:dssd_cuts}) are each adjusted separately at the start of data processing, and the changes are propagated through to a final $\chi^2$ map.  

The changes to measured values of $\bFierz$ and $\Abeta$ from these adjustments are comparatively small, and the errors are believed to be uncorrelated, so they are added in quadrature to the total systematic uncertainty.

%Although they don't all have an intuitively clear name, 

%%
%%BB1 radius cut can help to eliminate scattered events.  Energy threshold selection and statistical agreement between BB1 detectors' energies only makes a small effect on results.  BB1 radius itself has a pretty big effect on the result, but we can at least just G4 it away.  The remaining systematic effect is pretty small.  
\note[jb1]{JB:  I hope the discussion is clear in your head.  Any effect that relies on scattering computation in G4 should have an uncertainty on order 10\% of the correction -- hopefully you are keeping a distinction here between the finite geometry acceptance (which I guess is exact) scattering off the collimator.}
\note[jb1]{As per JB's comment in section~\ref{thesisconventionjb}:   ``statistical agreement between BB1 X and Y detectors' energies only makes a small effect on results" does not need the technical details beyond that statement."}
	
\missingfigure{Surely this requires at *least* one image of the pixelated BB1 data.  Maybe some of a few waveforms and energy distributions too.  ....Feels like cheating to include some of that stuff, since Ben was the one who actually used it mostly.}
\note[jb1]{JB on missing figure:  ``if you used such an image as part of your uncertainty estimate, yes [include it]''}

\note{Remember:  There's noise applied to simulated BB1s, matching some spectrum.}
\note{This probably should go somewhere else:  "In the end, we get our results from the scintillator energy only, without summing the BB1 energy back in.  Energy absorbed in DSSDs is only used as (a) a tag for events, and (b) contributing to the total beta energy loss before the beta arrives at the scintillator."}
\note[jb1]{JB:  The simulations of course include it event-by-event, not just a minimally ionizing average loss.}

%%%% --- * --- %%%%
\subsection{The Atomic Cloud}
\label{sec:lineshape_results}
\note{A lot of this content (in "The Atomic Cloud") has gone into (Section~\ref{sec:responsefunction}) instead.  I really need to just mention it here (Sec.~\ref{sec:lineshape_results}) and give an indication of how good the result is.  Then evaluate stuff.}
Uncertainties relating to the position, size, motion, and expansion of the atomic cloud are evaluated using the response function, which is implemented as described in Ch.~\ref{sec:responsefunction}. To evaluate how well the simple Monte Carlo + response function (SMC+RF) performs in evaluating uncertainties, the relationship between how the SMC+RF and the full G4 simulation changes when a BSM parameter is adjusted is considered in Fig.~\ref{fig:lineshape_demo}.

\begin{figure}[h!!!t]
	\centering
	\includegraphics[width=.999\linewidth]
	{Figures/LineshapeDemo_quasiprelim.png}
\note{This is a horrible and ugly picture, and it should be replaced.}
\caption[Response Function Comparison]{Superratio asymmetries generated by G4 and SMC+RF are compared against one another for a change in BSM parameters.  The results show a consistent behaviour when the value of $\bFierz$ is adjusted, suggesting that the SMC+RF can safely be used to evaluate systematic effects such as those arising from a change in cloud position.
%I'm not actually sure if this picture shows what I want it to.  The point is, if I apply this rough lineshape to stuff that I SimpleMC-ed, then I can evaluate that way various systematic effects that would be time-consuming to actually simulate with G4.  This picture is  *supposed* to be a demonstration that this approach actually works... 
}    	
	\label{fig:lineshape_demo}
\end{figure}

To evaluate the propagated systematic effects arising from our knowledge of the cloud position, the simple Monte Carlo is used to generate events originating at points chosen randomly from the distributions produced by linear interpolation of the parameters in Table~\ref{table:cloudpositions}, with each parameter describing the distribution allowed to vary in accordance with its stated uncertainty, assuming gaussian-distributed errors.  The results for each of the three datasets are shown in Fig.~\ref{fig:Abeta_position_err} for $\Abeta$ and Fig.~\ref{fig:bFierz_position_err} for $\bFierz$.


\begin{figure}[h!!tb]
	\centering
	\includegraphics[width=.999\linewidth]
	{Figures/Position_Err_Abeta.png}
	\caption[$\Abeta$ Position Error]{Estimated offset and uncertainty in $\Abeta$ resulting from an imperfectly centred cloud of finite size, and the uncertainty and variation within these parameters.  Evaluated by using the SMC+RF method.}	
	\label{fig:Abeta_position_err}
\end{figure}

\begin{figure}[h!!tb]
	\centering
	\includegraphics[width=.999\linewidth]
	{Figures/Position_Err_bFierz.png}
	\caption[$\bFierz$ Position Error]{Estimated offset and uncertainty in $\bFierz$ resulting from an imperfectly centred cloud of finite size, and the uncertainty and variation within these parameters.  Evaluated by using the SMC+RF method.}		
	\label{fig:bFierz_position_err}
\end{figure}



%%%% --- * --- %%%%
\FloatBarrier
\subsection{The Response Function's Low Energy Tail}
\note{Bremsstrahlung.  It does Bremsstrahlung.}
\note[done,nolist]{ Here is Subsection 9.5.5 ``The low-energy tail uncerainty, and what it does'' complete.  There should be no figure.
\\
Direct quote from John follows in the next two paragraphs.  Maybe I should paraphrase, but it's so nicely written! }

%\comment{
This subsection has the collaboration's evaluation of the uncertainty from
the scintillator detector's lineshape tail.
The energy from a monoenergetic beta is not always fully absorbed
in a plastic scintillator.
Although most backscattered betas are vetoed by the DSSD,
some produce bremsstrahlung photons,
and these frequently escape low-Z plastic scintillator-- all cross-sections
are known to high accuracy, but there is always uncertainty entailed in  the
MC implementation.
This lineshape tail will then effectively move events from higher to lower measured
energy, artificially altering the lower-energy asymmetries and mimicking the effects of a
Fierz term.

Since this detector effect is difficult to disentangle from the other scattering
effects off volumes,
the collaboration adds a linear function down to zero for the tail to
a Gaussian for the peak,
with linewidth varying by photon statistics~\cite{clifford}.
The convolution of this simple detector response function with v/c then scales the
centroid MC, with the lineshape tail varied by $\pm$10\% of its value,
a generic uncertainty accepted by the community for MC electromagnetic simulations.
The fit $b_{\rm Fierz}$ centroid changes by $\pm$ 0.0076, summarized
as the 0.008 ``Low Energy Tail'' within the systematics table in Sec.~\ref{sec:measured_limits}.
%the following chapter's Table~\ref{table:budget}.
When compared with other uncertainties of the present data set,
this is small enough that the accuracy of this estimate is adequate.
%}

\subsection{Background Events}
\label{section:background_events_systematics}
Modeling of background events is coverered comprehensively in Ch.~\ref{sec:tof_bg}.  Because the background model doesn't fully fit the experimental TOF spectrum, a relatively large variation in the number of background events is considered.  The background spectrum is scaled from its nominal size up by a factor of 2 and down by a factor of 2.  

Since the background has been reduced greatly by the improved time-of-flight
analysis, even this large variation in the number of background events makes a relatively small contribution to the final result.


\subsection{Material Thicknesses}
There are three distinct objects a beta emitted from the central atom cloud must pass through before arriving at a scintillator:  a $(275 \pm 6) \mu$m silicon carbide mirror, a $(229 \pm 23) \mu$m beryllium foil, and a $(295 \pm 5) \mu$m double-sided silicon strip detector, as shown in Fig.~\ref{chamber_decayevent}.~\aside{These numbers are really *not* what's shown in that picture.  The ones *here* are what I got from notes in my G4 scripts.  I don't know where the uncertainties came from before that.}

The propagated uncertainties are treated as uncorrelated (added in quadrature), and evaluated by running high-statistics Geant4 simulations with a parameter adjusted, then propagating the result through the analysis pipeline to compare against superratio asymmetries constructed to span the 2D BSM parameter space.  Because of the processor time required for this, certain simplifying assumptions were used to reduce the necessary number of simulations.  In particular, the top and bottom for each type of object were treated as producing the same size propagated uncertainty, though the top and bottom errors were not treated as being correlated.  Simulations were run to ensure there would not be any large nonlinear effects when combining a change in thickness for one type of object.  

Furthermore, since the DSSD and the mirror both have a similar density of silicon (which is the dominant material in causing scattering from the mirrors), and because the two both also have similar thickness values and uncertainties, the propagated uncertainties from the DSSDs and mirrors were assumed to produce similar sized effects on the result.  Thus, the uncertainties arising from uncertainties in the beryllium foil and mirror thicknesses were the only ones evaluated directly within Geant4.  The propagated uncertainty arising from DSSD thickness was assumed to be the same size as the uncertainty arising from mirror thicknesses.  

All uncertainties from material thicknesses are believed to be uncorrelated, and are added in quadrature to the final systematic uncertainty.  


 

